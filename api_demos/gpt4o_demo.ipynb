{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "client = openai.OpenAI(api_key=\"\")\n",
    "\n",
    "# Initialize conversation history\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an intelligent assistant capable of engaging in natural multi-turn conversations.\"},\n",
    "]\n",
    "\n",
    "def chat_with_gpt(user_input):\n",
    "    \"\"\"Handles text-only chat requests with GPT-4o.\"\"\"\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Send request to OpenAI GPT-4o\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Correctly access the response object\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    # Append AI response to conversation history\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    return reply\n",
    "\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def chat_with_image(image_path, user_input):\n",
    "    \"\"\"Handles image + text requests with GPT-4o.\"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # Attach the image in the proper format\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": user_input},  # Text input\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "        ]\n",
    "    })\n",
    "\n",
    "    # Send request to OpenAI GPT-4o\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Correctly access the response object\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    # Append AI response to conversation history\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})\n",
    "\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st round GPT-4o: Based on the image, let's proceed with the next movement:\n",
      "\n",
      "1. **Objective**: Approach the door and sign to check for the room number.\n",
      "\n",
      "2. **Movement Command**:\n",
      "   - **delta_x**: 2 (move forward to get closer to the door and sign)\n",
      "   - **delta_y**: 0 (no lateral movement)\n",
      "   - **delta_z**: 0 (maintain altitude)\n",
      "   - **delta_yaw**: 0 (no rotation)\n",
      "\n",
      "Execute this movement to get a clearer view of the sign. After moving, check if the room number \"407\" is visible or if further adjustments are necessary.\n",
      "\n",
      "\n",
      "2nd round GPT-4o (Image Response): The image shows a hallway with brick walls and a patterned floor. There’s a wooden door at the end of the hallway, with a dark rectangular sign or plaque on the wall next to it. \n",
      "\n",
      "To proceed, move the drone closer to the sign for better visibility:\n",
      "\n",
      "- **delta_x**: 2 (move forward to approach the door and sign)\n",
      "- **delta_y**: 0 (no lateral movement)\n",
      "- **delta_z**: 0 (maintain altitude)\n",
      "- **delta_yaw**: 0 (no rotation)\n",
      "\n",
      "This should help in reading the sign to check if it indicates Room 407.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_input = \"\"\"You are controlling a drone inside a school office building.  \n",
    "Your objective: Guide the drone to the entrance of Room 407.\n",
    "\n",
    "Important requirements:  \n",
    "1. The drone must actively search for room signs or any other identifiers (e.g., corridor signs, office nameplates).  \n",
    "2. If the sign or room number is partially or completely obscured, instruct the drone to adjust its position or yaw to obtain a clearer view.  \n",
    "3. Use small, incremental movements (Observation-Based Control) to avoid collisions, especially near glass walls or narrow corridors.  \n",
    "4. After each movement, carefully observe the updated camera feed for new indicators or obstacles.  \n",
    "5. Once you think you see the correct room (407), instruct the drone to perform a final check by hovering close enough to read the sign. If the sign is still not visible or the number is unclear, continue searching or try an alternative viewpoint.  \n",
    "6. If recognition remains ambiguous, try capturing a photo to confirm with an operator or look for adjacent rooms to cross-verify location.  \n",
    "\n",
    "Your control format (body frame, incremental moves):  \n",
    "Observation-Based Control (delta_x, delta_y, delta_z, delta_yaw)  \n",
    "- delta_x, delta_y, delta_z ∈ [-3, 3] (in meters)  \n",
    "- delta_yaw ∈ [-3.14, 3.14] (in radians)  \n",
    "- Right-hand rule for both body and world coordinate systems.  \n",
    "\n",
    "Now, look at the current camera feed:  \n",
    "Image is attached.  \n",
    "Based on the image, provide the next movement command to approach or identify Room 407.  \n",
    "If you cannot see any sign or the sign is unclear, consider rotating or shifting the drone for a better view.\n",
    "\"\"\"\n",
    "\n",
    "response = chat_with_gpt(user_input)\n",
    "print(\"1st round GPT-4o:\", response)\n",
    "\n",
    "\n",
    "image_response = chat_with_image(\"assets/pic1.PNG\", \"What do you see in this image?\")\n",
    "print(\"\\n\\n2nd round GPT-4o (Image Response):\", image_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
